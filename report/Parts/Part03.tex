\chapter{Post Effect Shaders \label{chap:postfx} }

While Raymarching is good for rendering infinite repetition scenes and soft shadows
the lack of knowledge about the data computed in other fragments prevents 
the system to apply some other effects to the scene.

That is why deferred shading has been implemented in this project. Every time we
render the quad with the Raymarcher shader instead the data, instead of being written in the standard
framebuffer, is written in different textures that will then be accessed by
the post effect shaders.

Since the project is based on node compositing every Post Effects shader writes
on its specific framebuffer, so that it is possible to change the order of the shaders
and chain them.

To render the final result on the screen a final shader is used, which simply
applies the texture computed by every post effect shader to the quad used for
Raymarching.

In this project six shaders have been implemented, but other could be easily
added. 

\section{Depth of Field and Bokeh}

One of the first post effects that came in mind during the development of the
project was the Depth of Field effect. The Depth of Field is the space of an image
in which the objects are sharp. The passage from sharp objects to blurred ones
is gradual, however. This space is given, normally by the distance of the object
from the camera, the focal length of the camera and such.

The Bokeh effect, on the other hand, is an optical aberration generated by
lights outside the depth of field of a picture. Everything that is outside the
depth of field, actually, concurrs to the Bokeh effect, but lights give out
the strongest effect. 

To achieve the same result it was needed to implement a shader that computed the depth
of field, used the distance from the camera to the objects and then applied
an andaptative blur based on the circle of confusion.

The problem with this approach, however, is the number of additional computations
per pixel that it introduces. The results, as seen in Figure \ref{img:DOF}, are
good, but it requires $5 + 10 + 15 = 30$ samples per pixel.

This is due by the part in the algorith where the confusion rings are computed and then used
to blur the pixel, as shown in Listing \ref{lst:ConfusionRings}. The \syntax{colorProcessing}
function is called to get the colour used for blurring and highlighting the pixel that is actually
computed.

\label{lst:ConfusionRings}\begin{lstlisting}
for (float i = 1.0; i <= depthRings; i ++)
	{
		float ringSamples = i * depthSamples;

		for (float j = 0.0 ; j < ringSamples ; j ++)
		{
			float blurStep = PI*2.0 / ringSamples;
			float pw = (cos(j * blurStep) * i);
			float ph = (sin(j * blurStep) * i);
			color += colorProcessing(coords +
						vec2(pw * w, ph * h), blur) *
						mix(1.0, i/depthRings, bokehBias);
			s += 1.0 * mix(1.0, i/depthRings, bokehBias);
		}
	}
\end{lstlisting}

\image{Images/DOF.png}{Depth Of Field post effect applied to the scene}{0.8}{img:DOF}

\section{Edge Detection}

  The edge detection algorithm used in this project makes full use of the depth buffer data to check whether a pixel is
  on the edge of an object or not.
  
  This way it is possible to render a colour on an edge to give a cel shading effect to the scene or to give the
  viewer a better idea of the shape of the objects.
  
  To know whether a pixel is on an edge the algorithm uses the distances of the sorrounding pixels dispalced on the x and
  y axis. By computing the difference is possible to know the gradient of distance and use that to render an edge or not.
  It is possible to make the algorithm recongnize even internal edges by applying a different coefficient to the computations
  of the distance delta, but the results are good with the used coefficients so it was decided not to let the user change 
  these coefficients in the compositor.
  
  \label{lst:EdgeDetect}\begin{lstlisting}
float ddx = abs((depth1 - depth0) - (depth0 - depth3));
float ddy = abs((depth2 - depth0) - (depth0 - depth4));
return clamp(clamp((ddx + ddy - 0.5) * 0.5,0.0,1.0)/(depth0 * 0.02), -1.0, 1.0);
  \end{lstlisting}

\image{Images/EdgeDetection.png}{Edge Detection post effect applied to the scene}{0.8}{img:EdgeDetect}

\section{Bloom}

  Bloom is the effect given by a high power light source in photography, where the light diffraction towards the edges
  of objects make the light bleed beyond the borders given by the objects. This happens because of the Airy Disc effect
  in photography and, while in standard light conditions this effect is not visible, when a high intensity light source is
  present in the scene this artifact is much more visible.
  
  Bloom is an effect that gives a more realistic effect, as shown in almost all of the more recent videogames (starting from
  \techname{ICO} on PS2), however it needs some tweaking on its coefficients, as it can get exaggerated.
  
  The main idea is, for each pixel, to sum the colour of the sorrounding pixels and then use this data based on the quantity
  of red of a single pixel: the higher the quantity, the lower the bloom effect. In listing \ref{lst:Bloom} the \syntax{bloomCoefficient}
  is multipled by $0.01$. This has been done to make it usable with sliders that go from $0.0$ to $100.0$.
  
  \label{lst:Bloom}\begin{lstlisting}
for( i = -4 ; i < 4; i++) {
  for (j = -3; j < 3; j++) {
    bloom += texture2D(inputImage, coords +
      vec2((j * 1.0 / windowSize.x), (i * 1.0 / windowSize.y)))
      * (bloomCoefficient * 0.01);
  }
}
  
if (texture2D(inputImage, coords).r < 0.3) {
  bloom = bloom * bloom * 0.012;
} else if (texture2D(inputImage, coords).r < 0.5) {
  bloom = bloom * bloom * 0.009;
} else {
  bloom = bloom * bloom *0.0075;
}
  \end{lstlisting}

\image{Images/Bloom.png}{Bloom post effect applied to the scene}{0.8}{img:Bloom}

\section{Radial Blur}

  Radial Blur is a simple effect used in videogames where the developers want to accentuate the speed of a scene.
  
  The main idea is to blur the pixels using the distance from a point (i.e. the centre) as power for this blurring and by sampling pixels
  toward that point. In this way the colour blends toward the external part of the image, making the scene looks as if it
  was moving faster. The \syntax{sampleStrength} and \syntax{sampleDist} parameters can be changed to make the effect
  more or less powerful.
  
  \begin{lstlisting}
float samples[10] = float[](-0.08,-0.05,-0.03,-0.02,-0.01,0.01,0.02,0.03,0.05,0.08);

vec2 dir = 0.5 - coords;
float distance = length(dir);
dir = normalize(dir);

vec4 color =  texture2D(inputImage, coords);
vec4 blurredcolor = color;

for (int i = 0; i < 10; i++) {
  blurredcolor += texture2D( inputImage, coords + dir * samples[i] * sampleDist )/11.0;
}

float t = distance * sampleStrength;
t = clamp( t ,0.0,1.0);

return mix( color, blurredcolor, t );
  \end{lstlisting}

\image{Images/RadialBlur.png}{Radial Blur post effect applied to the scene}{0.8}{img:RadialBlur}

\section{Sepia and Black \& White}

\image{Images/BlackAndWhite.png}{Black \& White post effect applied to the scene}{0.8}{img:BAW}
\image{Images/Sepia.png}{Sepia post effect applied to the scene}{0.8}{img:Sepia}
